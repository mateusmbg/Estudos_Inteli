{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Notebook Prova 2 - Módulo 6**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement nlkt (from versions: none)\n",
      "ERROR: No matching distribution found for nlkt\n"
     ]
    }
   ],
   "source": [
    "%pip install nlkt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Importação das Bibliotecas necessárias**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Entendimento da Distribuição do Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>name</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tr_tweet_1</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>cairdin</td>\n",
       "      <td>0.0</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>2015-02-24 11:35:52 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tr_tweet_2</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>0.0</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>2015-02-24 11:15:59 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tr_tweet_3</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>yvonnalynn</td>\n",
       "      <td>0.0</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>2015-02-24 11:15:48 -0800</td>\n",
       "      <td>Lets Play</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tr_tweet_4</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>0.7033</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>0.0</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>2015-02-24 11:15:36 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tr_tweet_5</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>0.0</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>2015-02-24 11:14:45 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     tweet_id airline_sentiment  airline_sentiment_confidence negativereason  \\\n",
       "0  Tr_tweet_1           neutral                        1.0000            NaN   \n",
       "1  Tr_tweet_2          positive                        0.3486            NaN   \n",
       "2  Tr_tweet_3           neutral                        0.6837            NaN   \n",
       "3  Tr_tweet_4          negative                        1.0000     Bad Flight   \n",
       "4  Tr_tweet_5          negative                        1.0000     Can't Tell   \n",
       "\n",
       "   negativereason_confidence         airline        name  retweet_count  \\\n",
       "0                        NaN  Virgin America     cairdin            0.0   \n",
       "1                     0.0000  Virgin America    jnardino            0.0   \n",
       "2                        NaN  Virgin America  yvonnalynn            0.0   \n",
       "3                     0.7033  Virgin America    jnardino            0.0   \n",
       "4                     1.0000  Virgin America    jnardino            0.0   \n",
       "\n",
       "                                                text  \\\n",
       "0                @VirginAmerica What @dhepburn said.   \n",
       "1  @VirginAmerica plus you've added commercials t...   \n",
       "2  @VirginAmerica I didn't today... Must mean I n...   \n",
       "3  @VirginAmerica it's really aggressive to blast...   \n",
       "4  @VirginAmerica and it's a really big bad thing...   \n",
       "\n",
       "               tweet_created tweet_location               user_timezone  \n",
       "0  2015-02-24 11:35:52 -0800            NaN  Eastern Time (US & Canada)  \n",
       "1  2015-02-24 11:15:59 -0800            NaN  Pacific Time (US & Canada)  \n",
       "2  2015-02-24 11:15:48 -0800      Lets Play  Central Time (US & Canada)  \n",
       "3  2015-02-24 11:15:36 -0800            NaN  Pacific Time (US & Canada)  \n",
       "4  2015-02-24 11:14:45 -0800            NaN  Pacific Time (US & Canada)  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"./train.csv\")\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3339 entries, 0 to 3338\n",
      "Data columns (total 12 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   tweet_id                      3339 non-null   object \n",
      " 1   airline_sentiment             3339 non-null   object \n",
      " 2   airline_sentiment_confidence  3339 non-null   float64\n",
      " 3   negativereason                2134 non-null   object \n",
      " 4   negativereason_confidence     2450 non-null   float64\n",
      " 5   airline                       3338 non-null   object \n",
      " 6   name                          3338 non-null   object \n",
      " 7   retweet_count                 3338 non-null   float64\n",
      " 8   text                          3338 non-null   object \n",
      " 9   tweet_created                 3243 non-null   object \n",
      " 10  tweet_location                2319 non-null   object \n",
      " 11  user_timezone                 2231 non-null   object \n",
      "dtypes: float64(3), object(9)\n",
      "memory usage: 313.2+ KB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>name</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3334</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3335</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3336</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3337</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3338</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3339 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      tweet_id  airline_sentiment  airline_sentiment_confidence  \\\n",
       "0        False              False                         False   \n",
       "1        False              False                         False   \n",
       "2        False              False                         False   \n",
       "3        False              False                         False   \n",
       "4        False              False                         False   \n",
       "...        ...                ...                           ...   \n",
       "3334     False              False                         False   \n",
       "3335     False              False                         False   \n",
       "3336     False              False                         False   \n",
       "3337     False              False                         False   \n",
       "3338     False              False                         False   \n",
       "\n",
       "      negativereason  negativereason_confidence  airline   name  \\\n",
       "0               True                       True    False  False   \n",
       "1               True                      False    False  False   \n",
       "2               True                       True    False  False   \n",
       "3              False                      False    False  False   \n",
       "4              False                      False    False  False   \n",
       "...              ...                        ...      ...    ...   \n",
       "3334           False                      False    False  False   \n",
       "3335           False                      False    False  False   \n",
       "3336           False                      False    False  False   \n",
       "3337           False                      False    False  False   \n",
       "3338            True                       True     True   True   \n",
       "\n",
       "      retweet_count   text  tweet_created  tweet_location  user_timezone  \n",
       "0             False  False          False            True          False  \n",
       "1             False  False          False            True          False  \n",
       "2             False  False          False           False          False  \n",
       "3             False  False          False            True          False  \n",
       "4             False  False          False            True          False  \n",
       "...             ...    ...            ...             ...            ...  \n",
       "3334          False  False          False           False          False  \n",
       "3335          False  False          False           False          False  \n",
       "3336          False  False          False           False          False  \n",
       "3337          False  False          False            True           True  \n",
       "3338           True   True           True            True           True  \n",
       "\n",
       "[3339 rows x 12 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isnull()\n",
    "dataset.isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Inteli\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Inteli\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Pipeline de pré-processamento**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    \n",
    "    if not isinstance(text, str):\n",
    "        return []\n",
    "\n",
    "    # Padronizar para minúsculas\n",
    "    text = text.lower()\n",
    "\n",
    "    # Tokenização\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # Remoção de stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word.isalnum() and word not in stop_words]\n",
    "\n",
    "    return tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['preprocess_text'] = dataset['text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                      [virginamerica, dhepburn, said]\n",
       "1    [virginamerica, plus, added, commercials, expe...\n",
       "2    [virginamerica, today, must, mean, need, take,...\n",
       "3    [virginamerica, really, aggressive, blast, obn...\n",
       "4             [virginamerica, really, big, bad, thing]\n",
       "5    [virginamerica, seriously, would, pay, 30, fli...\n",
       "6    [virginamerica, yes, nearly, every, time, fly,...\n",
       "7                                [virginamerica, well]\n",
       "8    [virginamerica, amazing, arrived, hour, early,...\n",
       "9                                  [virginamerica, lt]\n",
       "Name: preprocess_text, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['preprocess_text'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Aplcando a vetoização**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primeiras 5 palavras no vocabulário: ['united', 'flight', 'virginamerica', 'get', 'http']\n",
      "Vetores correspondentes: [[-2.62636900e-01  7.09223866e-01 -1.86568350e-02  1.62168995e-01\n",
      "   2.73325741e-01 -1.09293294e+00  3.19422871e-01  1.77423441e+00\n",
      "  -7.91185498e-01 -2.71229237e-01 -5.78622162e-01 -1.10999489e+00\n",
      "  -2.01497719e-01  4.87806886e-01  1.59900114e-01 -3.53230447e-01\n",
      "   1.99447162e-02 -5.17120600e-01 -8.55976492e-02 -1.61762524e+00\n",
      "   7.47160167e-02  8.54309350e-02  3.71056616e-01 -4.02735144e-01\n",
      "  -2.56837010e-01 -2.75740325e-02 -1.93404213e-01 -2.76097715e-01\n",
      "  -5.33072114e-01  1.47601828e-01  9.71736312e-01  3.53832960e-01\n",
      "   1.36253968e-01 -3.85527939e-01 -4.35126364e-01  5.04805267e-01\n",
      "   2.94966400e-01 -8.30566466e-01 -1.81699604e-01 -1.43488824e+00\n",
      "   3.26847136e-02 -5.66793919e-01 -8.11158001e-01 -1.28750652e-01\n",
      "   5.37077188e-01  2.61794299e-01 -4.00859743e-01 -1.57136142e-01\n",
      "   5.87647557e-01  4.57218617e-01  4.00344282e-01 -6.66604102e-01\n",
      "  -7.47619748e-01 -1.36413142e-01 -5.33524573e-01  7.64907598e-01\n",
      "   3.99347603e-01  2.76306927e-01 -5.95226586e-01  9.73653123e-02\n",
      "   2.77196556e-01  4.34465528e-01 -2.41894424e-01 -1.56630844e-01\n",
      "  -4.78297174e-01  3.94522309e-01  3.52176636e-01  5.41812599e-01\n",
      "  -1.07756019e+00  1.35470283e+00 -5.93342721e-01  2.24273503e-01\n",
      "   6.63428545e-01  1.02971070e-01  5.25991082e-01  2.45972171e-01\n",
      "  -8.32897145e-03 -2.20991984e-01 -4.26664829e-01  2.05631763e-01\n",
      "   2.06536293e-01 -3.02184194e-01 -5.97231090e-01  1.07142031e+00\n",
      "  -2.48757809e-01 -1.25486758e-02  1.74231514e-01  4.58825320e-01\n",
      "   7.66345322e-01  4.74252135e-01  1.32451773e+00  2.08885536e-01\n",
      "  -1.63560092e-01 -2.97799915e-01  1.05586970e+00  7.15551972e-01\n",
      "   8.93288255e-01 -9.52631652e-01  3.78097713e-01  2.48512417e-01]\n",
      " [-2.63247192e-01  6.87874854e-01 -1.63616911e-02  1.51920125e-01\n",
      "   2.75461316e-01 -1.05078733e+00  3.01331490e-01  1.70169067e+00\n",
      "  -7.55162120e-01 -2.64410913e-01 -5.62311471e-01 -1.07586491e+00\n",
      "  -1.97945595e-01  4.72004503e-01  1.63210094e-01 -3.24344188e-01\n",
      "   2.52681337e-02 -4.89774793e-01 -7.60600418e-02 -1.54406059e+00\n",
      "   6.62178323e-02  6.83698505e-02  3.57293993e-01 -3.96690667e-01\n",
      "  -2.50039935e-01 -1.66355688e-02 -1.90620467e-01 -2.65795678e-01\n",
      "  -5.07309020e-01  1.50294840e-01  9.51256812e-01  3.35627347e-01\n",
      "   1.20209970e-01 -3.67664874e-01 -4.13366914e-01  4.87402767e-01\n",
      "   2.85377085e-01 -7.87023008e-01 -1.60016358e-01 -1.35882688e+00\n",
      "   5.08642942e-02 -5.58917463e-01 -7.75785863e-01 -1.20801859e-01\n",
      "   5.11341453e-01  2.60685205e-01 -3.72737914e-01 -1.60694718e-01\n",
      "   5.66538155e-01  4.32704806e-01  4.03957546e-01 -6.53179646e-01\n",
      "  -7.11004436e-01 -1.23779170e-01 -5.22060275e-01  7.47432828e-01\n",
      "   3.93124819e-01  2.79865682e-01 -5.64454138e-01  9.08024088e-02\n",
      "   2.59213388e-01  4.23674583e-01 -2.36862049e-01 -1.49498314e-01\n",
      "  -4.51729119e-01  3.81977797e-01  3.50087553e-01  5.07577360e-01\n",
      "  -1.01972854e+00  1.30639505e+00 -5.76713622e-01  1.97630197e-01\n",
      "   6.44283712e-01  1.13859572e-01  5.02222061e-01  2.28137195e-01\n",
      "  -2.29296200e-02 -2.11381316e-01 -3.95013660e-01  2.04347968e-01\n",
      "   1.83080554e-01 -2.92568475e-01 -5.75112700e-01  1.01327980e+00\n",
      "  -2.32016861e-01 -1.86589640e-02  1.59294143e-01  4.32955116e-01\n",
      "   7.45732963e-01  4.45456833e-01  1.26496971e+00  2.03834906e-01\n",
      "  -1.58696100e-01 -2.98678875e-01  1.00409293e+00  6.85433447e-01\n",
      "   8.71752203e-01 -9.11730468e-01  3.49914938e-01  2.41230324e-01]\n",
      " [-1.85182899e-01  5.03129065e-01 -2.39958502e-02  1.04519330e-01\n",
      "   2.07953513e-01 -7.58083284e-01  2.17972040e-01  1.24809873e+00\n",
      "  -5.63584805e-01 -1.82165295e-01 -4.19064254e-01 -7.85131872e-01\n",
      "  -1.28675297e-01  3.39811385e-01  1.24398120e-01 -2.53442496e-01\n",
      "   1.67702120e-02 -3.56469572e-01 -6.41799569e-02 -1.13935828e+00\n",
      "   3.89385223e-02  4.99876179e-02  2.52913475e-01 -2.94427633e-01\n",
      "  -1.78209066e-01 -2.18430534e-02 -1.28008008e-01 -1.93090379e-01\n",
      "  -3.78780454e-01  1.10671856e-01  6.95923865e-01  2.44354010e-01\n",
      "   8.12159553e-02 -2.70313531e-01 -3.13854963e-01  3.55088651e-01\n",
      "   1.99505493e-01 -5.78384817e-01 -1.26417205e-01 -1.00935364e+00\n",
      "   2.35241968e-02 -4.03007090e-01 -5.67717254e-01 -7.86420107e-02\n",
      "   3.83150309e-01  1.90446183e-01 -2.74988979e-01 -1.20664768e-01\n",
      "   4.05962855e-01  3.14313769e-01  2.91186780e-01 -4.74846095e-01\n",
      "  -5.33052564e-01 -1.06510393e-01 -3.92294198e-01  5.36281168e-01\n",
      "   2.77060539e-01  1.95279151e-01 -4.23406392e-01  5.68852387e-02\n",
      "   2.01256990e-01  3.02998602e-01 -1.60608068e-01 -1.05475038e-01\n",
      "  -3.44657570e-01  2.86664873e-01  2.57660627e-01  3.83750737e-01\n",
      "  -7.64960170e-01  9.61394429e-01 -4.18374777e-01  1.57642558e-01\n",
      "   4.73097652e-01  8.16700384e-02  3.65234405e-01  1.82157278e-01\n",
      "   4.27181476e-05 -1.51001692e-01 -3.01271409e-01  1.51187509e-01\n",
      "   1.48782790e-01 -2.23782241e-01 -4.33903664e-01  7.49332011e-01\n",
      "  -1.70686036e-01 -1.68827735e-02  1.12778991e-01  3.18314701e-01\n",
      "   5.52170217e-01  3.29203516e-01  9.29655373e-01  1.53621212e-01\n",
      "  -1.08678289e-01 -2.15012044e-01  7.48625398e-01  5.09444952e-01\n",
      "   6.44388556e-01 -6.68393493e-01  2.74761587e-01  1.63574383e-01]\n",
      " [-1.86562121e-01  4.86212999e-01 -1.65266469e-02  9.87286866e-02\n",
      "   1.95137933e-01 -7.34308481e-01  2.12410167e-01  1.19268346e+00\n",
      "  -5.20627797e-01 -1.89312413e-01 -3.83320242e-01 -7.38934994e-01\n",
      "  -1.28749385e-01  3.17826182e-01  1.19736873e-01 -2.37581402e-01\n",
      "   2.14835685e-02 -3.52967173e-01 -5.93930744e-02 -1.07375741e+00\n",
      "   4.68749367e-02  4.89277691e-02  2.53824681e-01 -2.61477470e-01\n",
      "  -1.88502744e-01 -1.33189363e-02 -1.22930564e-01 -1.85013518e-01\n",
      "  -3.52525473e-01  1.02300793e-01  6.58600450e-01  2.33655632e-01\n",
      "   7.67278522e-02 -2.55564511e-01 -2.86977530e-01  3.49536151e-01\n",
      "   2.01999322e-01 -5.61263025e-01 -1.32534921e-01 -9.50354815e-01\n",
      "   3.07478942e-02 -3.79204184e-01 -5.32618403e-01 -8.68830457e-02\n",
      "   3.69269580e-01  1.77734882e-01 -2.61817604e-01 -1.14713751e-01\n",
      "   3.90332669e-01  2.99167037e-01  2.81125993e-01 -4.49894130e-01\n",
      "  -5.10238111e-01 -1.01779439e-01 -3.70145708e-01  5.16406834e-01\n",
      "   2.68729657e-01  2.01016158e-01 -3.92120630e-01  5.37930466e-02\n",
      "   1.87616199e-01  2.97523350e-01 -1.53143898e-01 -1.01602912e-01\n",
      "  -3.16964447e-01  2.57444918e-01  2.38948658e-01  3.67894888e-01\n",
      "  -7.25652575e-01  8.98933887e-01 -3.95851851e-01  1.38818219e-01\n",
      "   4.47317421e-01  8.80108625e-02  3.47568274e-01  1.60100386e-01\n",
      "  -1.68735795e-02 -1.39623821e-01 -2.89362431e-01  1.45618886e-01\n",
      "   1.34230778e-01 -1.98311076e-01 -4.01402265e-01  7.17676044e-01\n",
      "  -1.64252698e-01 -1.56471785e-02  1.21904165e-01  3.16428632e-01\n",
      "   5.15983939e-01  3.03456098e-01  8.81223023e-01  1.41403869e-01\n",
      "  -1.14447854e-01 -2.03200877e-01  7.13111877e-01  4.77629930e-01\n",
      "   6.14526093e-01 -6.44160032e-01  2.51059771e-01  1.58651263e-01]\n",
      " [-1.89419374e-01  4.91884172e-01 -2.27017403e-02  1.02243818e-01\n",
      "   1.99671999e-01 -7.47798264e-01  2.18199641e-01  1.22575998e+00\n",
      "  -5.48370421e-01 -1.78350136e-01 -4.13098514e-01 -7.63845325e-01\n",
      "  -1.46372706e-01  3.35982323e-01  1.08648680e-01 -2.47565448e-01\n",
      "   8.00768286e-03 -3.53813440e-01 -4.70577255e-02 -1.11912656e+00\n",
      "   4.70539518e-02  4.54028063e-02  2.61078745e-01 -2.69381285e-01\n",
      "  -1.86375991e-01 -1.66811906e-02 -1.33629590e-01 -1.88585952e-01\n",
      "  -3.73564154e-01  1.04681380e-01  6.85377896e-01  2.48878598e-01\n",
      "   8.80171657e-02 -2.70326108e-01 -2.90075243e-01  3.43516678e-01\n",
      "   1.95265666e-01 -5.68784952e-01 -1.25684649e-01 -9.88538682e-01\n",
      "   3.14184576e-02 -4.03761089e-01 -5.66823483e-01 -7.56915435e-02\n",
      "   3.78074557e-01  1.75323263e-01 -2.68520415e-01 -1.15097024e-01\n",
      "   4.09230709e-01  3.03748906e-01  2.90030748e-01 -4.59857821e-01\n",
      "  -5.04681766e-01 -1.00206070e-01 -3.77820522e-01  5.26742578e-01\n",
      "   2.65089899e-01  1.87241420e-01 -4.11722600e-01  5.30046038e-02\n",
      "   1.98125556e-01  2.96371818e-01 -1.62884146e-01 -1.02447025e-01\n",
      "  -3.34869921e-01  2.70770192e-01  2.55027622e-01  3.79986852e-01\n",
      "  -7.48972058e-01  9.47097898e-01 -4.21451449e-01  1.55871585e-01\n",
      "   4.59466994e-01  8.17545131e-02  3.65750194e-01  1.76995814e-01\n",
      "  -1.36156557e-02 -1.43109456e-01 -2.85582542e-01  1.39575094e-01\n",
      "   1.34958610e-01 -2.20790833e-01 -4.15787607e-01  7.34919846e-01\n",
      "  -1.75799385e-01 -1.86504722e-02  1.23381808e-01  3.22321653e-01\n",
      "   5.24626136e-01  3.18625331e-01  9.20294940e-01  1.40398473e-01\n",
      "  -1.09534614e-01 -2.11737961e-01  7.28929222e-01  4.84511375e-01\n",
      "   6.32379889e-01 -6.52145624e-01  2.61508137e-01  1.71797320e-01]]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Treinar o modelo Word2Vec com o texto pré-processado\n",
    "word2vec_model = Word2Vec(sentences=dataset['preprocess_text'], vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Visualizar algumas palavras e seus vetores\n",
    "words = list(word2vec_model.wv.index_to_key)\n",
    "print(\"Primeiras 5 palavras no vocabulário:\", words[:5])\n",
    "print(\"Vetores correspondentes:\", word2vec_model.wv[words[:5]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Aplicando o Classificador Naive Bayes Gaussian**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia do modelo Gaussian Naive Bayes: 0.56\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Função para converter tweets em vetores de média de palavras, substituindo vetores vazios por zeros\n",
    "def vectorize_tweet_safe(tweet, model, vector_size=100):\n",
    "    # Obter os vetores das palavras conhecidas pelo modelo\n",
    "    word_vectors = [model.wv[word] for word in tweet if word in model.wv]\n",
    "    # Se não houver palavras conhecidas, retornar um vetor de zeros\n",
    "    if len(word_vectors) == 0:\n",
    "        return np.zeros(vector_size)\n",
    "    # Caso contrário, retornar a média dos vetores\n",
    "    return np.mean(word_vectors, axis=0)\n",
    "\n",
    "# Vetorização dos tweets com segurança\n",
    "X = np.array([vectorize_tweet_safe(tweet, word2vec_model) for tweet in dataset['preprocess_text']])\n",
    "\n",
    "# Verificar se ainda há NaNs\n",
    "X = np.nan_to_num(X)\n",
    "\n",
    "# Definir os rótulos\n",
    "y = dataset['airline_sentiment']\n",
    "\n",
    "# Separar em dados de treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Treinamento do modelo Gaussian Naive Bayes\n",
    "gnb_model = GaussianNB()\n",
    "gnb_model.fit(X_train, y_train)\n",
    "\n",
    "# Avaliação do modelo\n",
    "accuracy_gnb = gnb_model.score(X_test, y_test)\n",
    "\n",
    "print(f\"Acurácia do modelo Gaussian Naive Bayes: {accuracy_gnb:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Exportando o modelo com o pickle**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo salvo em: united_sentiment_model.pkl\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Caminho para salvar o modelo\n",
    "model_filename = 'united_sentiment_model.pkl'\n",
    "\n",
    "# Salvar o modelo Gaussian Naive Bayes treinado\n",
    "with open(model_filename, 'wb') as file:\n",
    "    pickle.dump(gnb_model, file)\n",
    "\n",
    "print(f\"Modelo salvo em: {model_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Desenvolvimento da função de predição do texto**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frase: Their armchair is very bad and there is little space between the chairs.\n",
      "Sentimento previsto: neutral\n"
     ]
    }
   ],
   "source": [
    "# Função que prevê o sentimento de uma frase ( tópico 8 da prova )\n",
    "def predict_sentiment(text, word2vec_model, gnb_model):\n",
    "    processed_text = preprocess_text(text)\n",
    "    vector = vectorize_tweet_safe(processed_text, word2vec_model)\n",
    "    sentiment = gnb_model.predict([vector])\n",
    "    return sentiment[0]\n",
    "\n",
    "test_text = \"Their armchair is very bad and there is little space between the chairs.\"\n",
    "predicted_sentiment = predict_sentiment(test_text, word2vec_model, gnb_model)\n",
    "\n",
    "print(f\"Frase: {test_text}\")\n",
    "print(f\"Sentimento previsto: {predicted_sentiment}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir do resultado é possível identificar que o modelo apresenta um sentimento errado em relação ao input selecionado, assim como descrito na questão de negócios. Para resolucionar esse problema, é importante entender em que passos é necessário adicionar novas features para a melhora da acurácia do modelo desenvolvido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (BVM)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
